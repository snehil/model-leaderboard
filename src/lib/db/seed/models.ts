import type { NewModel } from "../schema";

// Models organized by organization slug
export const models: Record<string, Omit<NewModel, "organizationId">[]> = {
  openai: [
    {
      name: "GPT-5",
      slug: "gpt-5",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 256000,
      apiUrl: "https://platform.openai.com/docs/models/gpt-5",
      documentationUrl: "https://platform.openai.com/docs/models",
      description:
        "OpenAI's latest frontier model with enhanced reasoning and multimodal capabilities.",
      architecture: "Transformer",
    },
    {
      name: "GPT-4o",
      slug: "gpt-4o",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 128000,
      apiUrl: "https://platform.openai.com/docs/models/gpt-4o",
      documentationUrl: "https://platform.openai.com/docs/models",
      description:
        "OpenAI's most advanced multimodal model with vision, audio, and text capabilities.",
      architecture: "Transformer",
    },
    {
      name: "GPT-4 Turbo",
      slug: "gpt-4-turbo",
      modelType: "llm",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 128000,
      apiUrl: "https://platform.openai.com/docs/models/gpt-4-turbo",
      description: "High-intelligence flagship model for complex tasks.",
      architecture: "Transformer",
    },
    {
      name: "o1",
      slug: "o1",
      modelType: "reasoning",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://platform.openai.com/docs/models/o1",
      description:
        "Reasoning model trained with reinforcement learning for complex problem-solving.",
      architecture: "Transformer",
    },
    {
      name: "o3",
      slug: "o3",
      modelType: "reasoning",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://platform.openai.com/docs/models/o3",
      description:
        "OpenAI's most advanced reasoning model with breakthrough performance on complex tasks.",
      architecture: "Transformer",
    },
  ],
  anthropic: [
    {
      name: "Claude Opus 4.5",
      slug: "claude-opus-4-5",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://docs.anthropic.com/en/docs/models",
      documentationUrl: "https://docs.anthropic.com/",
      description:
        "Anthropic's most capable model with exceptional reasoning, coding, and creative abilities.",
      architecture: "Transformer",
    },
    {
      name: "Claude Sonnet 4",
      slug: "claude-sonnet-4",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://docs.anthropic.com/en/docs/models",
      documentationUrl: "https://docs.anthropic.com/",
      description:
        "Balanced performance and efficiency, excellent at coding and analysis.",
      architecture: "Transformer",
    },
    {
      name: "Claude 3.5 Sonnet",
      slug: "claude-3-5-sonnet",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://docs.anthropic.com/en/docs/models/claude-3-5-sonnet",
      documentationUrl: "https://docs.anthropic.com/",
      description:
        "Anthropic's previous generation high-performance model.",
      architecture: "Transformer",
    },
    {
      name: "Claude 3 Opus",
      slug: "claude-3-opus",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://docs.anthropic.com/en/docs/models/claude-3-opus",
      description: "Top-tier performance on highly complex tasks.",
      architecture: "Transformer",
    },
    {
      name: "Claude 3.5 Haiku",
      slug: "claude-3-5-haiku",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 200000,
      apiUrl: "https://docs.anthropic.com/en/docs/models/claude-3-5-haiku",
      description: "Fast and efficient model for everyday tasks.",
      architecture: "Transformer",
    },
  ],
  "google-deepmind": [
    {
      name: "Gemini 2.5 Pro",
      slug: "gemini-2-5-pro",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 1000000,
      apiUrl: "https://ai.google.dev/gemini-api/docs/models/gemini",
      description:
        "Google's most capable model with enhanced reasoning and coding abilities.",
      architecture: "Transformer (MoE)",
    },
    {
      name: "Gemini 2.5 Flash",
      slug: "gemini-2-5-flash",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 1000000,
      apiUrl: "https://ai.google.dev/gemini-api/docs/models/gemini",
      description:
        "Fast and efficient model with excellent speed-to-quality ratio.",
      architecture: "Transformer (MoE)",
    },
    {
      name: "Gemini 2.0 Flash",
      slug: "gemini-2-flash",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 1000000,
      apiUrl: "https://ai.google.dev/gemini-api/docs/models/gemini",
      description:
        "Google's latest multimodal model with 1M context window.",
      architecture: "Transformer",
    },
    {
      name: "Gemini 1.5 Pro",
      slug: "gemini-1-5-pro",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 2000000,
      apiUrl: "https://ai.google.dev/gemini-api/docs/models/gemini",
      description: "Mid-size multimodal model with 2M context.",
      architecture: "Transformer (MoE)",
    },
  ],
  meta: [
    {
      name: "Llama 3.1 405B",
      slug: "llama-3-1-405b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "405B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/meta-llama/Llama-3.1-405B",
      githubUrl: "https://github.com/meta-llama/llama3",
      paperUrl: "https://arxiv.org/abs/2407.21783",
      description:
        "Meta's largest open-weights model, competitive with frontier proprietary models.",
      architecture: "Transformer",
    },
    {
      name: "Llama 3.1 70B",
      slug: "llama-3-1-70b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "70B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/meta-llama/Llama-3.1-70B",
      description: "Strong open-weights model suitable for deployment.",
      architecture: "Transformer",
    },
    {
      name: "Llama 3.1 8B",
      slug: "llama-3-1-8b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "8B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/meta-llama/Llama-3.1-8B",
      description: "Efficient small model for edge deployment.",
      architecture: "Transformer",
    },
  ],
  mistral: [
    {
      name: "Mistral Large 2",
      slug: "mistral-large-2",
      modelType: "llm",
      licenseType: "proprietary",
      parameters: "123B",
      contextLength: 128000,
      apiUrl: "https://docs.mistral.ai/getting-started/models/",
      description:
        "Mistral's flagship model with top-tier reasoning capabilities.",
      architecture: "Transformer",
    },
    {
      name: "Mixtral 8x22B",
      slug: "mixtral-8x22b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "8x22B",
      contextLength: 65000,
      huggingfaceUrl: "https://huggingface.co/mistralai/Mixtral-8x22B-v0.1",
      description: "Sparse mixture-of-experts model with excellent efficiency.",
      architecture: "Transformer (MoE)",
    },
    {
      name: "Codestral",
      slug: "codestral",
      modelType: "code",
      licenseType: "open_weights",
      parameters: "22B",
      contextLength: 32000,
      huggingfaceUrl: "https://huggingface.co/mistralai/Codestral-22B-v0.1",
      description: "Specialized code generation model.",
      architecture: "Transformer",
    },
  ],
  deepseek: [
    {
      name: "DeepSeek-V3",
      slug: "deepseek-v3",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "671B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/deepseek-ai/DeepSeek-V3",
      githubUrl: "https://github.com/deepseek-ai/DeepSeek-V3",
      description:
        "Highly efficient MoE model with frontier performance at low cost.",
      architecture: "Transformer (MoE)",
    },
    {
      name: "DeepSeek-R1",
      slug: "deepseek-r1",
      modelType: "reasoning",
      licenseType: "open_weights",
      parameters: "671B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/deepseek-ai/DeepSeek-R1",
      description: "Reasoning model competitive with o1 at fraction of cost.",
      architecture: "Transformer (MoE)",
    },
  ],
  xai: [
    {
      name: "Grok-2",
      slug: "grok-2",
      modelType: "multimodal",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 128000,
      apiUrl: "https://docs.x.ai/",
      description: "xAI's frontier model with real-time knowledge.",
      architecture: "Transformer",
    },
  ],
  alibaba: [
    {
      name: "Qwen3 235B",
      slug: "qwen3-235b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "235B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/Qwen/Qwen3-235B",
      description: "Alibaba's largest and most capable open-weights model with frontier performance.",
      architecture: "Transformer (MoE)",
    },
    {
      name: "Qwen3 72B",
      slug: "qwen3-72b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "72B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/Qwen/Qwen3-72B",
      description: "High-performance open-weights model suitable for most tasks.",
      architecture: "Transformer",
    },
    {
      name: "Qwen2.5 72B",
      slug: "qwen-2-5-72b",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "72B",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/Qwen/Qwen2.5-72B",
      description: "Alibaba's previous generation large language model.",
      architecture: "Transformer",
    },
    {
      name: "Qwen2-VL 72B",
      slug: "qwen2-vl-72b",
      modelType: "multimodal",
      licenseType: "open_weights",
      parameters: "72B",
      contextLength: 32000,
      huggingfaceUrl: "https://huggingface.co/Qwen/Qwen2-VL-72B",
      description: "Vision-language model with strong multimodal capabilities.",
      architecture: "Transformer",
    },
  ],
  moonshot: [
    {
      name: "Kimi K2",
      slug: "kimi-k2",
      modelType: "llm",
      licenseType: "open_weights",
      parameters: "1T (MoE)",
      contextLength: 128000,
      huggingfaceUrl: "https://huggingface.co/moonshotai/Kimi-K2-Instruct",
      description: "Moonshot's frontier MoE model with excellent reasoning and coding abilities.",
      architecture: "Transformer (MoE)",
    },
    {
      name: "Kimi K1.5",
      slug: "kimi-k1-5",
      modelType: "reasoning",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 128000,
      apiUrl: "https://platform.moonshot.cn",
      description: "Reasoning model with strong performance on complex tasks.",
      architecture: "Transformer",
    },
  ],
  bytedance: [
    {
      name: "Doubao Pro",
      slug: "doubao-pro",
      modelType: "llm",
      licenseType: "proprietary",
      parameters: "Unknown",
      contextLength: 128000,
      apiUrl: "https://www.volcengine.com/product/doubao",
      description: "ByteDance's flagship large language model.",
      architecture: "Transformer",
    },
  ],
};
